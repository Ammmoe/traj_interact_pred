2025-12-02 12:41:30,227 - INFO - 
================================================================================
Starting New Inference Session
================================================================================
2025-12-02 12:41:30,227 - INFO - Using device: cpu
2025-12-02 12:41:30,227 - INFO - Experiment folder: experiments/20251201_180721
2025-12-02 12:41:30,227 - INFO - Inference batch size: 1
2025-12-02 12:41:30,227 - INFO - Agents padded during dataset preparation: [0, 4, 5]
2025-12-02 12:41:30,525 - INFO - Starting inference on test dataset...
2025-12-02 12:43:49,510 - INFO - Total inference time: 138.98 seconds
2025-12-02 12:43:49,510 - INFO - Average inference time per batch: 0.0340 seconds
2025-12-02 12:43:49,510 - INFO - Average inference time per sequence: 0.0340 seconds
2025-12-02 12:43:49,524 - INFO - Inference Evaluation Metrics:
2025-12-02 12:43:49,524 - INFO - Accuracy: 0.9997, Precision: 0.9990, Recall: 1.0000, F1: 0.9995
2025-12-02 12:43:49,524 - INFO - Confusion Matrix:
[[5753    2]
 [   0 1921]]
2025-12-02 12:43:49,815 - INFO - Final Inference Accuracy: 0.9997
2025-12-02 12:46:19,811 - INFO - 
================================================================================
Starting New Inference Session
================================================================================
2025-12-02 12:46:19,811 - INFO - Using device: cpu
2025-12-02 12:46:19,812 - INFO - Experiment folder: experiments/20251201_180721
2025-12-02 12:46:19,812 - INFO - Inference batch size: 1
2025-12-02 12:46:19,812 - INFO - Agents padded during dataset preparation: [0, 2, 4, 5]
2025-12-02 12:46:20,101 - INFO - Starting inference on test dataset...
2025-12-02 12:48:34,978 - INFO - Total inference time: 134.88 seconds
2025-12-02 12:48:34,979 - INFO - Average inference time per batch: 0.0330 seconds
2025-12-02 12:48:34,979 - INFO - Average inference time per sequence: 0.0330 seconds
2025-12-02 12:48:34,991 - INFO - Inference Evaluation Metrics:
2025-12-02 12:48:34,991 - INFO - Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
2025-12-02 12:48:34,991 - INFO - Confusion Matrix:
[[1951    0]
 [   0  788]]
2025-12-02 12:48:35,279 - INFO - Final Inference Accuracy: 1.0000
2025-12-02 12:49:45,642 - INFO - 
================================================================================
Starting New Inference Session
================================================================================
2025-12-02 12:49:45,642 - INFO - Using device: cpu
2025-12-02 12:49:45,642 - INFO - Experiment folder: experiments/20251201_180721
2025-12-02 12:49:45,643 - INFO - Inference batch size: 1
2025-12-02 12:49:45,643 - INFO - Agents padded during dataset preparation: [1, 3, 4]
2025-12-02 12:49:45,938 - INFO - Starting inference on test dataset...
2025-12-02 12:52:05,810 - INFO - Total inference time: 139.87 seconds
2025-12-02 12:52:05,811 - INFO - Average inference time per batch: 0.0342 seconds
2025-12-02 12:52:05,811 - INFO - Average inference time per sequence: 0.0342 seconds
2025-12-02 12:52:05,831 - INFO - Inference Evaluation Metrics:
2025-12-02 12:52:05,831 - INFO - Accuracy: 0.9985, Precision: 0.9970, Recall: 0.9987, F1: 0.9979
2025-12-02 12:52:05,831 - INFO - Confusion Matrix:
[[4457    7]
 [   3 2351]]
2025-12-02 12:52:06,150 - INFO - Final Inference Accuracy: 0.9985
2025-12-02 12:54:05,718 - INFO - 
================================================================================
Starting New Inference Session
================================================================================
2025-12-02 12:54:05,718 - INFO - Using device: cpu
2025-12-02 12:54:05,718 - INFO - Experiment folder: experiments/20251201_180721
2025-12-02 12:54:05,719 - INFO - Inference batch size: 1
2025-12-02 12:54:05,719 - INFO - Agents padded during dataset preparation: None
2025-12-02 12:54:06,012 - INFO - Starting inference on test dataset...
2025-12-02 12:56:41,963 - INFO - Total inference time: 155.95 seconds
2025-12-02 12:56:41,964 - INFO - Average inference time per batch: 0.0381 seconds
2025-12-02 12:56:41,964 - INFO - Average inference time per sequence: 0.0381 seconds
2025-12-02 12:56:42,002 - INFO - Inference Evaluation Metrics:
2025-12-02 12:56:42,003 - INFO - Accuracy: 0.9982, Precision: 0.9984, Recall: 0.9960, F1: 0.9972
2025-12-02 12:56:42,003 - INFO - Confusion Matrix:
[[24539    19]
 [   49 12230]]
2025-12-02 12:56:42,345 - INFO - Final Inference Accuracy: 0.9982
2025-12-02 12:59:31,515 - INFO - 
================================================================================
Starting New Inference Session
================================================================================
2025-12-02 12:59:31,516 - INFO - Using device: cpu
2025-12-02 12:59:31,516 - INFO - Experiment folder: experiments/20251201_180721
2025-12-02 12:59:31,516 - INFO - Inference batch size: 1
2025-12-02 12:59:31,516 - INFO - Agents padded during dataset preparation: [1, 3]
2025-12-02 12:59:31,820 - INFO - Starting inference on test dataset...
2025-12-02 13:01:54,720 - INFO - Total inference time: 142.90 seconds
2025-12-02 13:01:54,722 - INFO - Average inference time per batch: 0.0349 seconds
2025-12-02 13:01:54,722 - INFO - Average inference time per sequence: 0.0349 seconds
2025-12-02 13:01:54,744 - INFO - Inference Evaluation Metrics:
2025-12-02 13:01:54,744 - INFO - Accuracy: 0.9981, Precision: 0.9968, Recall: 0.9974, F1: 0.9971
2025-12-02 13:01:54,744 - INFO - Confusion Matrix:
[[10042    16]
 [   13  4928]]
2025-12-02 13:01:55,044 - INFO - Final Inference Accuracy: 0.9981
2025-12-02 17:09:13,758 - INFO - 
================================================================================
Starting New Inference Session
================================================================================
2025-12-02 17:09:13,758 - INFO - Using device: cpu
2025-12-02 17:09:13,758 - INFO - Experiment folder: experiments/20251201_180721
2025-12-02 17:09:13,758 - INFO - Inference batch size: 32
2025-12-02 17:09:13,758 - INFO - Agents padded during dataset preparation: [1, 3]
2025-12-02 17:09:14,054 - INFO - Starting inference on test dataset...
2025-12-02 17:11:24,799 - INFO - Total inference time: 130.75 seconds
2025-12-02 17:11:24,801 - INFO - Average inference time per batch: 1.0214 seconds
2025-12-02 17:11:24,801 - INFO - Average inference time per sequence: 0.0319 seconds
2025-12-02 17:11:24,814 - INFO - Inference Evaluation Metrics:
2025-12-02 17:11:24,814 - INFO - Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
2025-12-02 17:11:24,814 - INFO - Confusion Matrix:
[[12279     0]
 [    0  4093]]
2025-12-02 17:11:25,109 - INFO - Final Inference Accuracy: 1.0000
